import { NextResponse } from 'next/server'; // Replace with your actual API key if necessary (or use environment variable) const apiKey = process.env.GEMINI_API_KEY || 'AIzaSyC6JxeeL_pWFjZ4EAXEq6XXtFpSOi2vqr4'; export async function POST(req: Request) { try { const { image, question } = await req.json(); if (!question) { return NextResponse.json({ error: 'No question provided' }, { status: 400 }); } // If we have an image, use multimodal endpoint, otherwise use text-only const response = image ? await processImageAndQuestion(image, question) : await processTextQuestion(question); return NextResponse.json({ result: response }); } catch (error) { console.error('Error processing the request:', error); return NextResponse.json( { error: 'An error occurred while processing the request' }, { status: 500 } ); } } async function processTextQuestion(question: string) { const geminiEndpoint = `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${apiKey}`; const payload = { contents: [ { parts: [ { text: `You are a fashion expert AI assistant providing helpful and accurate fashion advice. ${question}`, }, ], }, ], generationConfig: { temperature: 0.7, maxOutputTokens: 800, }, }; try { const response = await fetch(geminiEndpoint, { method: 'POST', headers: { 'Content-Type': 'application/json', }, body: JSON.stringify(payload), }); if (!response.ok) { const errorData = await response.json(); console.error('Error from Gemini API:', errorData); return 'Error communicating with the AI model.'; } const data = await response.json(); const result = data?.candidates?.[0]?.content?.parts?.[0]?.text; return result || 'No response from the model.'; } catch (error) { console.error('Error calling Gemini API:', error); return 'Error communicating with the AI model.'; } } async function processImageAndQuestion(image: string, question: string) { if (!image) { return 'No image data received.'; } const geminiEndpoint = `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${apiKey}`; const imageData = image.split(',')[1]; // Remove data URL prefix const mimeType = image.substring(image.indexOf(":") + 1, image.indexOf(";")); const payload = { contents: [ { parts: [ { inline_data: { mime_type: mimeType, data: imageData, }, }, { text: `You are a fashion expert AI assistant analyzing this image and providing helpful advice. ${question}`, }, ], }, ], generationConfig: { temperature: 0.7, maxOutputTokens: 800, }, }; try { const response = await fetch(geminiEndpoint, { method: 'POST', headers: { 'Content-Type': 'application/json', }, body: JSON.stringify(payload), }); if (!response.ok) { const errorData = await response.json(); console.error('Error from Gemini API:', errorData); return 'Error communicating with the AI model.'; } const data = await response.json(); const result = data?.candidates?.[0]?.content?.parts?.[0]?.text; return result || 'No response from the model.'; } catch (error) { console.error('Error calling Gemini API:', error); return 'Error communicating with the AI model.'; } } 