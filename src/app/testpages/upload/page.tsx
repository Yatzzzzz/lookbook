'use client'; import React, { useRef, useState, useEffect } from 'react'; import { Camera, Upload, X, RefreshCw, Tag, Check, Trash } from 'lucide-react'; export default function UploadPage() { const videoRef = useRef<HTMLVideoElement>(null); const canvasRef = useRef<HTMLCanvasElement>(null); const fileInputRef = useRef<HTMLInputElement>(null); const [image, setImage] = useState<string | null>(null); const [stream, setStream] = useState<MediaStream | null>(null); const [cameraActive, setCameraActive] = useState(false); const [loading, setLoading] = useState(false); const [error, setError] = useState<string | null>(null); const [tags, setTags] = useState<string[]>([]); const [analysisMode, setAnalysisMode] = useState<string>('tag'); const [showManualTagInput, setShowManualTagInput] = useState(false); const [manualTagInput, setManualTagInput] = useState(''); const [capturedImage, setCapturedImage] = useState<string | null>(null); const [showImagePreview, setShowImagePreview] = useState(false); // Clean up camera resources when component unmounts useEffect(() => { return () => { if (stream) { stream.getTracks().forEach(track => track.stop()); } }; }, [stream]); const startCamera = async () => { try { setError(null); console.log('Starting camera...'); // Request camera access, preferring environment (rear) camera const mediaStream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } }); console.log('Camera access granted, stream obtained:', mediaStream); setStream(mediaStream); setCameraActive(true); // Just activate the camera UI, will handle video in useEffect } catch (err) { console.error('Camera error:', err); setError('Failed to access camera. Please check permissions or try file upload instead.'); setCameraActive(false); } }; // Add a useEffect hook to handle the video element after it's rendered useEffect(() => { if (cameraActive && stream && videoRef.current) { console.log('Setting video source in useEffect...'); videoRef.current.srcObject = stream; videoRef.current.onloadedmetadata = () => { console.log('Video metadata loaded'); // Ensure video plays videoRef.current?.play().catch(e => { console.error('Error playing video:', e); setError('Failed to play video stream'); }); }; } }, [cameraActive, stream]); const stopCamera = () => { if (stream) { stream.getTracks().forEach(track => track.stop()); setStream(null); setCameraActive(false); if (videoRef.current) { videoRef.current.srcObject = null; } } }; const captureImage = () => { if (!videoRef.current || !canvasRef.current) { setError('Camera not properly initialized'); return; } const video = videoRef.current; const canvas = canvasRef.current; const context = canvas.getContext('2d'); if (!context) { setError('Could not get canvas context'); return; } // Set canvas dimensions to match video canvas.width = video.videoWidth; canvas.height = video.videoHeight; // Draw the current video frame to the canvas context.drawImage(video, 0, 0, canvas.width, canvas.height); try { // Convert canvas to data URL const imageDataUrl = canvas.toDataURL('image/jpeg', 0.8); // 0.8 quality for compression setCapturedImage(imageDataUrl); setShowImagePreview(true); } catch (err) { console.error('Error capturing image:', err); setError('Failed to capture image'); } }; const approveImage = () => { if (capturedImage) { setImage(capturedImage); stopCamera(); setShowImagePreview(false); // Automatically analyze the captured image analyzeImage(capturedImage); } }; const rejectImage = () => { setCapturedImage(null); setShowImagePreview(false); // Keep camera active for another capture }; const handleFileUpload = (e: React.ChangeEvent<HTMLInputElement>) => { const file = e.target.files?.[0]; if (!file) return; setError(null); setLoading(true); const reader = new FileReader(); reader.onload = (event) => { const imageDataUrl = event.target?.result as string; setImage(imageDataUrl); analyzeImage(imageDataUrl); }; reader.onerror = () => { setError('Failed to read the selected file'); setLoading(false); }; reader.readAsDataURL(file); }; const analyzeImage = async (imageData: string) => { setTags([]); setLoading(true); setError(null); setShowManualTagInput(false); try { // First try our new testpages API endpoint const res = await fetch('/api/testpages/clothes-finder', { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify({ imageBase64: imageData, mode: analysisMode }) }); if (!res.ok) { const errorData = await res.json(); throw new Error(errorData.error || `API error: ${res.status}`); } const result = await res.json(); if (Array.isArray(result.tags)) { setTags(result.tags); } else if (typeof result.tags === 'string') { setTags(result.tags.split('\n').filter((tag: string) => tag.trim())); } else { setTags([]); setError('Could not process analysis results'); } } catch (err: unknown) { console.error('Error analyzing image:', err); const errorMessage = err instanceof Error ? err.message : 'Failed to analyze the image'; setError(`${errorMessage}. You can add tags manually.`); setShowManualTagInput(true); } finally { setLoading(false); } }; const addManualTag = () => { if (manualTagInput.trim()) { setTags([...tags, manualTagInput.trim()]); setManualTagInput(''); } }; const removeTag = (index: number) => { setTags(tags.filter((_, i) => i !== index)); }; const resetAll = () => { setImage(null); setCapturedImage(null); setShowImagePreview(false); setTags([]); setError(null); setLoading(false); setShowManualTagInput(false); setManualTagInput(''); if (fileInputRef.current) { fileInputRef.current.value = ''; } }; return ( <div className="max-w-4xl mx-auto"> <h1 className="text-2xl font-bold mb-4">Upload & Camera</h1> {/* Mode selector */} <div className="mb-4"> <h2 className="text-sm font-medium mb-2">Analysis Type:</h2> <div className="flex space-x-2"> {['tag', 'detail', 'style'].map((mode) => ( <button key={mode} onClick={() => setAnalysisMode(mode)} className={`px-3 py-1 rounded-md text-sm ${ mode === analysisMode ? 'bg-blue-600 text-white' : 'bg-gray-200 text-gray-800 ' }`} > {mode.charAt(0).toUpperCase() + mode.slice(1)} </button> ))} </div> </div> {/* Camera UI */} {!image && ( <div className="bg-gray-100 rounded-lg p-4 mb-4"> {cameraActive ? ( <div className="space-y-4"> <div className="relative w-full h-[300px] bg-gray-100 border border-gray-300 rounded-md overflow-hidden"> {showImagePreview && capturedImage ? ( <img src={capturedImage} alt="Captured preview" className="w-full h-full object-cover" /> ) : ( <> <video ref={videoRef} autoPlay playsInline muted className="w-full h-full object-cover" /> <button onClick={stopCamera} className="absolute top-2 right-2 bg-red-500 p-2 rounded-full text-white z-10" aria-label="Stop camera" > <X size={18} /> </button> </> )} {/* Capture controls */} {!showImagePreview && ( <div className="absolute bottom-4 left-0 right-0 flex justify-center"> <button onClick={captureImage} className="bg-blue-600 text-white px-4 py-2 rounded-full hover:bg-blue-700 flex items-center" > <Camera size={18} className="mr-2" /> Take Photo </button> </div> )} {/* Approval controls */} {showImagePreview && capturedImage && ( <div className="absolute bottom-4 left-0 right-0 flex justify-center space-x-4"> <button onClick={rejectImage} className="flex items-center gap-2 bg-red-500 text-white px-4 py-2 rounded-full hover:bg-red-600 transition-colors" > <Trash size={18} /> Retake </button> <button onClick={approveImage} className="flex items-center gap-2 bg-green-500 text-white px-4 py-2 rounded-full hover:bg-green-600 transition-colors" > <Check size={18} /> Approve </button> </div> )} </div> </div> ) : ( <div className="p-8 text-center"> <Camera className="mx-auto h-12 w-12 text-gray-400 mb-2" /> <p className="text-lg font-medium">Capture or upload a fashion image</p> <p className="text-sm text-gray-600 mt-1"> We&apos;ll analyze your clothing items and provide fashion insights </p> <div className="flex flex-col sm:flex-row justify-center gap-4 mt-6"> <button onClick={startCamera} className="flex items-center justify-center px-4 py-2 bg-blue-600 text-white rounded-md hover:bg-blue-700" > <Camera size={18} className="mr-2" /> Start Camera </button> <label className="flex items-center justify-center px-4 py-2 bg-gray-200 text-gray-800 rounded-md hover:bg-gray-300 cursor-pointer"> <Upload size={18} className="mr-2" /> Upload Photo <input ref={fileInputRef} type="file" accept="image/*" className="hidden" onChange={handleFileUpload} /> </label> </div> </div> )} <canvas ref={canvasRef} className="hidden" /> </div> )} {/* Image preview */} {image && ( <div className="bg-gray-100 rounded-lg p-4 mb-4"> <div className="grid grid-cols-1 md:grid-cols-2 gap-4"> <div> <div className="relative"> <img src={image} alt="Captured clothing" className="rounded-md w-full" /> <button onClick={resetAll} className="absolute top-2 right-2 bg-red-500 p-2 rounded-full text-white" aria-label="Remove image" > <X size={18} /> </button> </div> <div className="mt-2 flex justify-between"> <button onClick={resetAll} className="flex items-center px-3 py-1 bg-gray-200 text-gray-800 rounded-md hover:bg-gray-300 text-sm" > <RefreshCw size={14} className="mr-1" /> New Image </button> <button onClick={() => analyzeImage(image)} className="flex items-center px-3 py-1 bg-blue-600 text-white rounded-md hover:bg-blue-700 text-sm" disabled={loading} > {loading ? 'Analyzing...' : 'Reanalyze'} </button> </div> </div> <div> <h3 className="font-medium mb-2">Analysis Results:</h3> {loading ? ( <div className="flex items-center justify-center h-40 bg-white rounded-md p-4"> <div className="animate-spin rounded-full h-8 w-8 border-2 border-t-blue-500 border-gray-300"></div> </div> ) : error ? ( <div className="bg-red-100 p-3 rounded-md text-red-700 text-sm mb-3"> {error} </div> ) : null} {/* Tags */} {tags.length > 0 && ( <div className="bg-white rounded-md p-3"> <div className="flex flex-wrap gap-2"> {tags.map((tag, index) => ( <div key={index} className="flex items-center bg-blue-100 text-blue-800 px-2 py-1 rounded-md text-sm" > {tag} <button onClick={() => removeTag(index)} className="ml-1 text-blue-700 hover:text-red-500" > <X size={14} /> </button> </div> ))} </div> </div> )} {/* Manual tag input */} {(showManualTagInput || tags.length > 0) && ( <div className="mt-3"> <div className="flex items-center space-x-2"> <input type="text" value={manualTagInput} onChange={(e) => setManualTagInput(e.target.value)} placeholder="Add manual tag..." className="px-3 py-1 border border-gray-300 rounded-md flex-1 bg-white " onKeyDown={(e) => e.key === 'Enter' && addManualTag()} /> <button onClick={addManualTag} className="flex items-center px-3 py-1 bg-green-600 text-white rounded-md" > <Tag size={14} className="mr-1" /> Add </button> </div> </div> )} </div> </div> </div> )} {/* Info section */} <div className="bg-blue-50 p-4 rounded-lg text-sm"> <h3 className="font-medium mb-1">About this feature:</h3> <p className="text-gray-700 "> This component implements a comprehensive upload and camera integration with AI-powered clothing analysis. It uses the Gemini API to analyze clothing items and accessories in your images. </p> <p className="text-gray-700 mt-2"> The analysis modes offer different levels of detail: </p> <ul className="list-disc pl-5 mt-1 space-y-1 text-gray-700 "> <li><strong>Tag</strong>: Simple list of clothing items and colors</li> <li><strong>Detail</strong>: Comprehensive description of each item</li> <li><strong>Style</strong>: Overall style analysis and recommendations</li> </ul> </div> </div> ); } 